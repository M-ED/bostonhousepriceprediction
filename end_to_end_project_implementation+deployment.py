# -*- coding: utf-8 -*-
"""End_to_End_Project_Implementation+Deployment.ipynb

#Automatically generated by Colaboratory.

#Original file is located at
 #   https://colab.research.google.com/drive/1-8Ub3sCWqg6SGjejTi_-KCFFfTJdNmDJ

## **End to End Project Implementation Deployment**
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

"""## **Lets load the Boston House Pricing Dataset**"""

from sklearn.datasets import load_boston

boston=load_boston()

type(boston)

boston.keys()

## CHeck description of dataset
print(boston.DESCR)

print(boston.data)

print(boston.target)

print(boston.feature_names)

"""## **Preparing the Dataset**"""

dataset=pd.DataFrame(boston.data, columns=boston.feature_names)

dataset.head()

dataset['Price']=boston.target

dataset.head()

dataset.info()

## Summarizing the stats of the data.
dataset.describe()

## Check the missing value
dataset.isnull()

dataset.isnull().sum()

"""## **Exploratory Data Analysis**"""

## Correlation
dataset.corr( )

## import seaborn as sns
## sns.pairplot(dataset)

plt.scatter(dataset['CRIM'], dataset['Price'])
plt.xlabel("Crime Rate")
plt.ylabel("Price")

plt.scatter(dataset['RM'], dataset['Price'])
plt.xlabel("RM")
plt.ylabel("Price")

import seaborn as sns
sns.regplot(x="RM", y="Price", data=dataset)

sns.regplot(x="LSTAT", y="Price", data=dataset)

sns.regplot(x="CHAS", y="Price", data=dataset)

sns.regplot(x='PTRATIO', y='Price', data=dataset)

"""## **Creating a Model**"""

## Dependent and independent features.

X=dataset.iloc[:,:-1]
y=dataset.iloc[:,-1]

### Train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=0)

X_train

## Standardize the dataset
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

X_train=scaler.fit_transform(X_train)

X_test=scaler.fit_transform(X_test)

import pickle
pickle.dump(scaler, open('scaling.pkl', 'wb'))

X_train

X_test

"""## **Model Training**"""

from sklearn.linear_model import LinearRegression

regression=LinearRegression()

regression.fit(X_train, y_train)

## Print the coefficient and intercept
## This is a number of all the independent features for every
## independent feature I have a number of independent feature.
print(regression.coef_)

print(regression.intercept_)

## On which parameters the model has been trained
regression.get_params()

## prediction with the test data
reg_pred=regression.predict(X_test)

reg_pred

### plot a scatter plot for prediction
plt.scatter(y_test,reg_pred)

## Residuals
residuals=y_test-reg_pred

residuals

## Plot the dist plot
sns.displot(residuals, kind="kde")

## Scatter plot with respect to prediction and residuals
## uniform distribution of a data
plt.scatter(reg_pred, residuals)

## We can use a performance metrics.
from sklearn.metrics import mean_squared_error

from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_test, reg_pred))
print(mean_squared_error(y_test, reg_pred))
print(np.sqrt(mean_squared_error(y_test, reg_pred)))

"""## **New Data Prediction**"""

boston.data[0].shape

boston.data[0].reshape(1, -1)

## Transformation of new data
scaler.transform(boston.data[0].reshape(1, -1))

regression.predict(scaler.transform(boston.data[0].reshape(1, -1)))

"""## **Pickling the model file for deployment**"""

import pickle

## This pickle application would be in the serialized form.
pickle.dump(regression,open('regmodel.pkl', 'wb'))

pickled_model=pickle.load(open('regmodel.pkl', 'rb'))

pickled_model.predict(scaler.transform(boston.data[0].reshape(1, -1)))

